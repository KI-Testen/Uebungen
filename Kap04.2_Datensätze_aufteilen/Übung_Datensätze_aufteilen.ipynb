{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "64503883-b510-4891-af0c-9959ffcfa317",
            "metadata": {
                "deletable": true,
                "tags": []
            },
            "source": [
                "# \u00dcbung zu Kapitel 4.2 - Datens\u00e4tze aufteilen\n",
                "\n",
                "*Eine \u00dcbung zum Buch \"[Basiswissen KI-Testen - Qualit\u00e4t von und mit KI-basierten Systemen](https://dpunkt.de/produkt/basiswissen-ki-testen/)\", ISBN 978-3-86490-947-4*\n",
                "\n",
                "In dieser \u00dcbung besch\u00e4ftigen wir uns mit der Aufteilung von Datens\u00e4tzen in **Trainings-, Validierungs- und Testdatens\u00e4tze**. Dazu verwenden wir wieder den Iris-Datensatz, den du schon in der [vorherigen \u00dcbung (4.1)](../Kap04.1_Datenvorbereitung/\u00dcbung_Datenaufbereitung.ipynb) aufbereitet hast.\n",
                "Wir nutzen hier wieder mehrere Bibliotheken, die daf\u00fcr passende Methoden bereithalten:\n",
                "\n",
                "[<img src=\"https://pandas.pydata.org/docs/_static/pandas.svg\" alt=\"pandas\" width=\"80\" height=\"24\">](https://pandas.pydata.org/docs/reference/index.html)\n",
                "&emsp; [<img src=\"https://numpy.org/doc/stable/_static/numpylogo.svg\" alt=\"Numpy\" width=\"80\" height=\"24\">](https://numpy.org/doc/stable/reference/index.html#reference)\n",
                "&emsp; [<img src=\"https://scikit-learn.org/stable/_static/scikit-learn-logo-small.png\" alt=\"Scikit-learn\" width=\"80\" height=\"24\">](https://scikit-learn.org/stable/modules/classes.html)\n",
                "&emsp; [<img src=\"https://matplotlib.org/_static/logo_light.svg\" alt=\"Matplotlib\" width=\"100\" height=\"24\">](https://matplotlib.org/)\n",
                "&emsp; [<img src=\"https://docs.scipy.org/doc/scipy/_static/logo.svg\" alt=\"SciPy\" width=\"24\" height=\"24\"> SciPy](https://docs.scipy.org/doc/scipy/index.html)\n",
                "&emsp; [<img src=\"https://joblib.readthedocs.io/en/stable/_static/joblib_logo.svg\" alt=\"joblib\" width=\"36\" height=\"36\"> joblib](https://joblib.readthedocs.io/en/stable)\n",
                "\n",
                "Die \u00dcbung ist in drei Aufgaben und eine vierte Zusatzaufgabe eingeteilt:\n",
                "1. Aufteilen der Datens\u00e4tze\n",
                "2. Trainieren eines ML-Klassifikators\n",
                "3. Diskussion der Ergebnisse\n",
                "4. *Zusatzaufgabe: k-fache Kreuzvalidierung*\n",
                "\n",
                "zum Schluss speichern wir das Modell des ML-Klassifikators noch ab, um es in der n\u00e4chsten Aufgabe verwenden zu k\u00f6nnen."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "890c2373-0b86-43f3-b4a6-91594a6fc758",
            "metadata": {
                "tags": []
            },
            "source": [
                "## Aufgabe 1\n",
                "\n",
                "**Teile die in der praktischen [\u00dcbung 4.1](../Kap04.1_Datenvorbereitung/%C3%9Cbung_Datenvorbereitung.ipynb) vorbereiteten Daten in Trainings-, Validierungs- und Testdatens\u00e4tze auf.\n",
                "Die Daten sollen im Verh\u00e4ltnis 80:10:10 aufgeteilt sein.**\n",
                "\n",
                "Die Aufteilung in diese drei Datens\u00e4tze machen wir Schritt f\u00fcr Schritt.\n",
                "1. Einlesen der Daten und Trennung von Input (X) und Output (y)\n",
                "1. Aufteilen der Eingabe- und Ausgabewerte in jeweils Trainings/Validierungs- und Testdatens\u00e4tze\n",
                "1. Weiteres Aufteilen in Trainings- und Validierungsdatens\u00e4tze"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f79468f3-a13f-44ce-b095-fbdbb8e3ac2b",
            "metadata": {
                "tags": []
            },
            "source": [
                "**1. Lade zur Vorbereitung den Iris-Datensatz und teile diesen nach Input-Daten X und Output-Daten y auf.**\n",
                "\n",
                "Die Input-Daten (Eingabewerte) speichern wir dabei als Matrix in der Variablen `X` ab. Die zugeh\u00f6rigen Output-Daten (Klassifikationsergebnis) speichern wir in der Variablen `y`.\n",
                "Du hast in der vorangehenden \u00dcbung den Iris-Datensatz als CSV-Datei vorbereitet und kannst diesen nun mit der Funktion [read_csv](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) der _Pandas_-Bibliothek laden.\n",
                "\n",
                "Erg\u00e4nze im folgenden Code die mit `...` gekennzeichneten Teile:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2e8b53ad-6e6c-471a-a77c-65e0ff6f2531",
            "metadata": {
                "tags": [
                    "Aufgabe"
                ]
            },
            "outputs": [],
            "source": [
                "import pandas as pd         # pandas Bibliothek verwenden\n",
                "iris = pd.read_csv(...)     # hier den Pfad zur CSV-Datei angeben, die du in \u00dcbung 4.1 Datenvorbereitung erzeugt hast"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1d8035a0-1706-4501-a806-7e566e9c1a6d",
            "metadata": {
                "scrolled": true,
                "tags": [
                    "L\u00f6sung"
                ],
                "jupyter": {
                    "source_hidden": true
                }
            },
            "outputs": [],
            "source": [
                "# Um die L\u00f6sung anzuzeigen, bitte diese Zelle zweimal ausf\u00fchren\n",
                "%load L\u00f6sungen/L\u00f6sung01.py"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5739f845-1eb6-4388-ab5b-f13700e2df7a",
            "metadata": {
                "tags": []
            },
            "source": [
                "Pandas gibt mit der Funktion `read_csv` die Daten als Objekt vom Typ \"[DataFrame](https://pandas.pydata.org/docs/reference/frame.html)\" zur\u00fcck, die wir in der Variablen `iris` gespeichert haben.\n",
                "Pr\u00fcfe kurz die geladenen Daten, ob Du die richtige Datei genommen hast. Du kannst daf\u00fcr z.B. mit der Methode [head()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html) die ersten Zeilen im Datensatz ansehen. Schau Dir die Dokumentation der Methode an (Link anklicken) und erg\u00e4nze den Code:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ff02dab3-aaa9-4233-b87f-274b7c7c4855",
            "metadata": {
                "tags": [
                    "Aufgabe"
                ]
            },
            "outputs": [],
            "source": [
                "iris...     # Pr\u00fcfe die ersten Eintr\u00e4ge der Daten"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9086cdaf-330f-47c0-ae5e-1a4e147b3732",
            "metadata": {
                "tags": [
                    "L\u00f6sung"
                ],
                "jupyter": {
                    "source_hidden": true
                }
            },
            "outputs": [],
            "source": [
                "# Um die L\u00f6sung anzuzeigen, bitte diese Zelle zweimal ausf\u00fchren\n",
                "%load L\u00f6sungen/L\u00f6sung02.py"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b524a234-cdc7-4a95-ad4b-d34342c0443b",
            "metadata": {
                "tags": []
            },
            "source": [
                "Teile nun dieses Datenarray in zwei auf: eines als Eingabedatensatz (X) und eines als Ausgabedatensatz (y).\n",
                "Dabei kannst du die Methode [drop()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html) benutzen um z.&nbsp;B. eine bestimmte Spalte zu l\u00f6schen, und die Methode [filter()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.filter.html) um eine bestimmte Spalte herauszuholen (und den Rest zu ignorieren)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e0104060-9fe4-46c8-ac25-9636c2657f24",
            "metadata": {
                "tags": [
                    "Aufgabe"
                ]
            },
            "outputs": [],
            "source": [
                "X = iris.drop(...)\n",
                "y = iris.filter(...)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "182c36f2-7d01-406d-8ca4-d2524a62a524",
            "metadata": {
                "tags": [
                    "L\u00f6sung"
                ],
                "jupyter": {
                    "source_hidden": true
                }
            },
            "outputs": [],
            "source": [
                "# Um die L\u00f6sung anzuzeigen, bitte diese Zelle zweimal ausf\u00fchren\n",
                "%load L\u00f6sungen/L\u00f6sung03.py"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "75938a5d-5c83-4179-b0ae-4486f329e333",
            "metadata": {
                "tags": []
            },
            "source": [
                "Lass uns pr\u00fcfen, ob der 1. Schritt richtig war: Wir schauen uns die Abmessungen der Arrays _(Zeilen, Spalten)_ an. Beide m\u00fcssen 150 Zeilen (also alle Datensatzeintr\u00e4ge) haben. `X` enth\u00e4lt vier Eingabewerte (4 Spalten) und `y` einen Ausgabewert (1 Spalte).\n",
                "Dazu benutzen wir die Eigenschaft [.shape](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shape.html) des DataFrames."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d276276d-7b87-4ba6-8820-f792d63bdc16",
            "metadata": {
                "tags": [
                    "Test"
                ]
            },
            "outputs": [],
            "source": [
                "# Pr\u00fcfung von Schritt 1.1 - stimmen die Abmessungen der Arrays?\n",
                "(X.shape == (150,4) and      \n",
                " y.shape == (150,1))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "71534b5b-7547-4021-8d56-a7b51c1012f7",
            "metadata": {},
            "source": [
                "Wir k\u00f6nnen uns auch noch die ersten 5 Datensatzeintr\u00e4ge von `X` und `y` ansehen und mit der Ausgabe (oben) vergleichen, in der wir `iris.head()` benutzt haben, um die ersten Eintr\u00e4ge des Pandas DataFrames `iris` anzusehen."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "005d4c3e-989d-4bae-bb5e-8dbc63f618ab",
            "metadata": {
                "tags": [
                    "Test"
                ]
            },
            "outputs": [],
            "source": [
                "# Pr\u00fcfung von Schritt 1.1 - Daten ansehen, ob diese vermutlich stimmen.\n",
                "X[0:5], y[0:5]"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a163421b-68b9-4e31-ab0a-9fc13f02619c",
            "metadata": {
                "tags": []
            },
            "source": [
                "**2. Teile jetzt jeweils die Input- (X) und Outputdaten (y) zuerst in einen Trainings/Validierungs-Datensatz `_trainval` und einen Testdatensatz `_test` auf. Die weitere Aufteilung kommt im 3. Schritt.**\n",
                "\n",
                "Dazu benutzen wir die Funktion **train_test_split()** aus der Bibliothek scikit-learn, die gleichzeitig Input- und Outputdaten jeweils in *zwei* Teile aufteilt. Wir machen hier also nur den *ersten* von zwei Aufteilung-Schritten:\n",
                "\n",
                "![Image](data/data_split_Xy.png)\n",
                "\n",
                "Sieh dir die Beschreibung von [train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split) an und erg\u00e4nze die mit `...` gekennzeichneten Parameter, so dass am Ende die Verh\u00e4ltnisse **Training : Validierung : Test** den Anteilen **80 : 10 : 10** entsprechen."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "33329581-1412-4a12-a314-55ab105bc7e3",
            "metadata": {
                "tags": [
                    "Aufgabe"
                ]
            },
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split   # importiere diese Methode aus der Bibliothek scikit-learn\n",
                "\n",
                "# Wir setzten den Parameter random_state f\u00fcr die Reproduzierbarkeit der Ergebnisse auf einen festen Wert (4)\n",
                "X_trainval, X_test, y_trainval, y_test = train_test_split( ... , test_size=..., random_state=4 )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5eb7e8c0-e6cd-4e29-ac2c-279d375bea17",
            "metadata": {
                "tags": [
                    "L\u00f6sung"
                ],
                "jupyter": {
                    "source_hidden": true
                }
            },
            "outputs": [],
            "source": [
                "# Um die L\u00f6sung anzuzeigen, bitte diese Zelle zweimal ausf\u00fchren\n",
                "%load L\u00f6sungen/L\u00f6sung04.py"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ef7bbc1c-6dec-4c81-a8bd-3edbe122c9bb",
            "metadata": {},
            "source": [
                "*Anmerkung: Die Funktion train_test_split() ordnet vor dem Aufteilen die Dateneintr\u00e4ge in einer zuf\u00e4llige Reihenfolge an. Das Argument `random_state=...` setzt den daf\u00fcr verwendeten Pseudo-Zufallsgenerator auf den angegebenen Startwert. So kann - trotz \"Zufallskomponente\" - reproduzierbar das gleiche Aufteilungsergebnis erzeugt werden.*\n",
                "\n",
                "Wir **pr\u00fcfen**, ob die Menge des Testdatensatzes stimmt: Dieser soll 10% der 150 Zeilen enthalten, also 15. Au\u00dferdem pr\u00fcfen wir, ob die Zeilenzahlen beider Anteile ('trainval' und 'test') zusammen 150 ergeben."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d774f652-1973-4cf9-a143-58f79d751eb0",
            "metadata": {
                "tags": [
                    "Test"
                ]
            },
            "outputs": [],
            "source": [
                "# Pr\u00fcfung von Schritt 1.2 - Stimmt die Abmessung des Testdatensatzes (10% der 150 Zeilen)?\n",
                "(X_test.shape == (15,4) and\n",
                " y_test.shape == (15,1))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "344714c8-e0ed-4d6a-9ddc-2980f41afdb3",
            "metadata": {
                "tags": [
                    "Test"
                ]
            },
            "outputs": [],
            "source": [
                "# Pr\u00fcfung von Schritt 1.2 - Haben wir keine Daten 'verloren' und ist die Summe der Zeilen (.shape[0]) 150?\n",
                "(X_trainval.shape[0] + X_test.shape[0] == 150 and\n",
                " y_trainval.shape[0] + y_test.shape[0] == 150)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9f3d4335-2e1e-449c-a1c7-29280417e9aa",
            "metadata": {},
            "source": [
                "**3. Teile jetzt den Trainings/Validierungs-Datensatz im zweiten Schritt weiter auf in `_train` (Training) und `_val` (Validation).**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8b41b527-bd14-45e3-9488-505c52493ff3",
            "metadata": {
                "tags": [
                    "Aufgabe"
                ]
            },
            "outputs": [],
            "source": [
                "X_train, X_val, y_train, y_val = train_test_split( ... , test_size=..., random_state=6 ) # bitte random_state bei 6 belassen"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ec3eddc1-3b2e-42a1-8667-2da6ce19b15f",
            "metadata": {
                "tags": [
                    "L\u00f6sung"
                ],
                "jupyter": {
                    "source_hidden": true
                }
            },
            "outputs": [],
            "source": [
                "# Um die L\u00f6sung anzuzeigen, bitte diese Zelle zweimal ausf\u00fchren\n",
                "%load L\u00f6sungen/L\u00f6sung05.py"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7f4ee9bd-5f03-48e9-b972-dfb877a62729",
            "metadata": {},
            "source": [
                "Wir pr\u00fcfen auch hier ob die Abmessung des Validierungsdatensatzes stimmt: Auch dieser soll 10% der 150 Zeilen haben."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3859de8f-baae-44f5-aaef-407aa9f27baa",
            "metadata": {
                "tags": [
                    "Test"
                ]
            },
            "outputs": [],
            "source": [
                "# Simple Pr\u00fcfung von Schritt 1.3 - Stimmt die Abmessung des Validierungsdatensatzes?\n",
                "(X_val.shape == (15,4) and\n",
                " y_val.shape == (15,1))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e1df78bf-de29-4057-8cf0-ee8cbdb4020f",
            "metadata": {},
            "source": [
                "Als letztes pr\u00fcfen wir den Trainingsdatensatz, der 80% der 150 Zeile enthalten muss, also 120:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "19646719-16b6-406b-98fc-2c5551f03eb1",
            "metadata": {
                "tags": [
                    "Test"
                ]
            },
            "outputs": [],
            "source": [
                "# Simple Pr\u00fcfung von Schritt 1.3 - Stimmt die Abmessung des Trainingsdatensatzes?\n",
                "(X_train.shape == (120,4)  and\n",
                " y_train.shape == (120,1))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a883e0bc-6fd0-4b9e-b2ae-c5a3ef4cf31b",
            "metadata": {},
            "source": [
                "## Aufgabe 2\n",
                "\n",
                "**Trainiere mit den Trainings- und Validierungsdatens\u00e4tzen einen Klassifikator mit Hilfe eines [Entscheidungsbaums](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) und ermittle dessen Genauigkeit \u00fcber alle Ergebnisklassen.**\n",
                "\n",
                "Wir benutzen hier einen Entscheidungsbaum [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html), bei dem wir als *Hyperparameter* angeben k\u00f6nnen, welche maximale Tiefe (`max_depth=`) dieser haben soll. Benutze den folgenden Code, um das Modell anhand der Trainingsdaten zu **trainieren** und die **Genauigkeit** des Modells anhand der Trainings- und der Validierungsdaten zu ermitteln.\n",
                "\n",
                "Starte mit einer `max_depth=1` und erh\u00f6he diese Schritt f\u00fcr Schritt und beobachte die Genauigkeiten! Wann kannst du aufh\u00f6ren?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fcebc25d-e898-427f-89d4-cec4f3d2c970",
            "metadata": {
                "tags": [
                    "Aufgabe"
                ]
            },
            "outputs": [],
            "source": [
                "from sklearn import tree   # Wir benutzen das Entscheidungsbaum-Modell (tree) der Bibliothek scikit-learn\n",
                "\n",
                "# Einen Entscheidungsbaum mit maximaler Tiefe ... erzeugen und per '.fit()'-Methode mit den Trainigsdaten trainieren\n",
                "model_dtree = tree.DecisionTreeClassifier(max_depth=...)\n",
                "model_dtree.fit(X_train, y_train)\n",
                "\n",
                "# Die Genauigkeit \u00fcber alle Ergebnisklassen ermitteln: \"Wieviel Prozent der Ergebnisse waren richtig?\"\n",
                "print('Tiefe des Entscheidungsbaums: {0}'.format(model_dtree.get_depth()))\n",
                "print('Die Genauigkeit auf den Trainingsdaten    liegt bei {0:3.2f}%'.format(model_dtree.score(X_train,y_train)*100))\n",
                "print('Die Genauigkeit auf den Validierungsdaten liegt bei {0:3.2f}%'.format(model_dtree.score(X_val,  y_val  )*100))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0fdd8e9d-81e4-426a-b09d-021d76626875",
            "metadata": {
                "tags": [
                    "L\u00f6sung"
                ],
                "jupyter": {
                    "source_hidden": true
                }
            },
            "outputs": [],
            "source": [
                "# Um die L\u00f6sung anzuzeigen, bitte diese Zelle zweimal ausf\u00fchren\n",
                "%load L\u00f6sungen/L\u00f6sung06.py"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e24d1530-9f1c-49b9-beb2-e5633292d460",
            "metadata": {
                "tags": []
            },
            "source": [
                "Wie du siehst, verbessert sich die Genauigkeit je gr\u00f6\u00dfer die Tiefe des Entscheidungsbaums wird. Ab einer Tiefe von 4 trifft der Entscheidungsbaum 100% aller Trainingsdaten richtig.\n",
                "\n",
                "Lass uns das **in einem Bild** darstellen (wir nutzen die [matplotlib](https://matplotlib.org/stable/index.html) Bibliothek daf\u00fcr): Wir programmieren eine Schleife (`for d in ...`), um den Teil des obigen Codes, der das Modell trainiert und die Genauigkeit berechnet, mehrmals auszuf\u00fchren. Dabei \u00e4ndern wir nun automatisch (vorher hast du das manuell gemacht) die maximale Tiefe des Modells im Bereich von 1 bis 8.\n",
                "\n",
                "Wir stellen aber nicht mehr die Genauigkeit dar, sondern tragen auf der y-Achse den **Fehler** (1-Genauigkeit) auf."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9bef67d2-b638-493d-8e75-3b4c1f8829b4",
            "metadata": {
                "tags": [
                    "Test"
                ]
            },
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt   # Wir benutzen die Bibliothek matplot zum Zeichnen der Grafik\n",
                "\n",
                "# Daten-Arrays f\u00fcr die Grafik vorbereiten\n",
                "max_depths  = range(1, 9) # = [1,2,3,4,5,6,7,8]\n",
                "error_train = []          # in diesem Array sammeln wir die Fehlerrate mit den Trainingsdaten\n",
                "error_val   = []          # in diesem Array sammeln wir die Fehlerrate mit den Validierungsdaten\n",
                "\n",
                "# F\u00fcr alle Werte in der Liste der maximalen Baumtiefen das Modell trainieren und die Fehler berechnen\n",
                "for d in max_depths:\n",
                "    model = tree.DecisionTreeClassifier(max_depth=d)     # Modell erzeugen\n",
                "    model.fit(X_train,y_train)                           # trainieren\n",
                "    error_train.append(1 - model.score(X_train,y_train)) # Fehler (Trainingsdaten) an Array anh\u00e4ngen\n",
                "    error_val.append  (1 - model.score(X_val,  y_val))   # Fehler (Validierungsdaten) an Array anh\u00e4ngen\n",
                "\n",
                "# Grafik erzeugen\n",
                "fig, ax = plt.subplots()              # Ein Bild (fig) mit einem Diagramm (ax) anlegen.\n",
                "ax.set_xlabel('maximum tree depth')   # x-Achsenbeschriftung\n",
                "ax.set_ylabel('error')                # y-Achsenbeschriftung\n",
                "ax.plot(max_depths, error_train, label='Training') # Zeichne die Entwicklung des Fehlers mit den Trainingsdaten\n",
                "ax.plot(max_depths, error_val, label='Validation') # Zeichne die Entwicklung des Fehlers mit den Validierungsdaten\n",
                "ax.legend();                                       # Zeichne die Legende"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "81bc9704-7fe3-43c5-ab67-2ed37c9a4f83",
            "metadata": {},
            "source": [
                "Die Grafik zeigt, wie sich der Fehler mit zunehmender Baumtiefe verringert (Die Genauigkeit nimmt zu.). Ab Tiefe 4 ist der Fehler sowohl bei Trainings- als auch bei den Testdaten bei 0. Der Entscheidungsbaum ist also anscheinend perfekt (auf die Trainingsdaten) trainiert.\n",
                "\n",
                "**Genauigkeit \u00fcber alle Ergebnisklassen zusammen:**\n",
                "\n",
                "Stimmt das wirklich? Bei anderen Trainingsmethoden l\u00e4sst sich n\u00e4mlich nicht vermeiden, dass sich das Modell indirekt auch auf die Validierungsdaten anpasst. Daher **pr\u00fcfen** wir das Modell nun nochmal mit den **Testdaten**:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7a567d2a-6fa9-49bb-95b8-809cae7b10f1",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(model.score(X_test,  y_test))\n",
                "print('Die Genauigkeit mit den Testdaten liegt bei {0:3.2f}%'.format(model.score(X_test,  y_test)*100))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6d6ab3f5-6ca0-4d7d-91f0-15568efd2445",
            "metadata": {},
            "source": [
                "## Aufgabe 3\n",
                "\n",
                "**Worin liegt der Unterschied zwischen Validierung und Test? Vergleiche dazu die jeweils erzielten Genauigkeiten.**\n",
                "\n",
                "In unserer \u00dcbung haben wir einen einfachen Entscheidungsbaum trainiert. Die Daten f\u00fcr Training, Validierung und Test haben wir mit der Split-Methode aufgeteilt. Die entstehenden Genauigkeiten lauten - wenn wir diese f\u00fcr alle drei Datens\u00e4tze vergleichen:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f418c294-66b0-4009-afa0-bfeba1f639cb",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "def genauigkeit(): # Wir definieren hier eine Funktion (ohne Argumente - die Klammer ist leer) ...\n",
                "    print('Decision Tree der Tiefe {0}'.format(model_dtree.get_depth()))\n",
                "    acc_train = model_dtree.score(X_train, y_train)*100\n",
                "    acc_val   = model_dtree.score(X_val,   y_val  )*100\n",
                "    acc_test  = model_dtree.score(X_test,  y_test )*100\n",
                "    print(f\" - Die Genauigkeit auf den Trainingsdaten    liegt bei {acc_train:3.2f}%\")\n",
                "    print(f\" - Die Genauigkeit auf den Validierungsdaten liegt bei {acc_val:3.2f}%\")\n",
                "    print(f\" - Die Genauigkeit auf den Testdaten         liegt bei {acc_test:3.2f}%\")\n",
                "\n",
                "genauigkeit()      # ... und benutzen diese hier (die Funktion ist nun bekannt und kann auch in den anderen Zellen benutzt werden)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0459b14d-a101-4590-a4e1-5b11022f0044",
            "metadata": {},
            "source": [
                "Sehen die Werte immer so aus? Probiere unterschiedliche `random_state`-Werte f\u00fcr die Aufteilung in die Datens\u00e4tze aus, indem du die passenden Code-Teile von oben hierher kopierst und einfach ausprobierst:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a829b57e-920b-4411-b4e8-89be2040d16f",
            "metadata": {
                "tags": [
                    "Aufgabe"
                ]
            },
            "outputs": [],
            "source": [
                "# iris-Datensatz (X) und (y) in Trainings-, Validierungs- und Testdatensatz aufteilen\n",
                "...\n",
                "\n",
                "# den Entscheidungsbaum mit maximaler Tiefe 8 erzeugen und per '.fit()'-Methode mit den Trainigsdaten trainieren\n",
                "...\n",
                "\n",
                "# die Genauigkeit auf allen drei Datens\u00e4tzen vergleichen\n",
                "genauigkeit()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "da6d4f62-abcc-4aee-aad2-57d80fac9394",
            "metadata": {
                "tags": [
                    "L\u00f6sung"
                ],
                "jupyter": {
                    "source_hidden": true
                }
            },
            "outputs": [],
            "source": [
                "# Um die L\u00f6sung anzuzeigen, bitte diese Zelle zweimal ausf\u00fchren\n",
                "%load L\u00f6sungen/L\u00f6sung07.py"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "eafc3b3a-7fbc-4dd3-adfa-bcd65afc8e91",
            "metadata": {
                "tags": [
                    "Aufgabe"
                ]
            },
            "source": [
                "**Ein paar Fragen die du dir stellen kannst:**\n",
                "* Was beobachtest du?\n",
                "* Warum ist das so?\n",
                "* Was w\u00e4re, wenn wir statt der Split-Methode die k-fache Kreuzvalidierung (k-fold cross validation) verwenden w\u00fcrden?"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "aab19dbc-01c9-44d1-b5d6-50c495df04fa",
            "metadata": {
                "tags": [
                    "L\u00f6sung"
                ],
                "jupyter": {
                    "source_hidden": true
                }
            },
            "source": [
                "**Was beobachten wir und warum ist das so?**\n",
                "\n",
                "* Die Genauigkeit auf den **Trainingsdaten** liegt praktisch konstant bei 100%. Das ist nicht weiter verwunderlich, denn wir haben mit 120 Datenpunkten einen vergleichsweise kleinen Trainingsdatensatz. F\u00fcr den Entscheidungsbaum (maximale Tiefe 8) ist es daher ein Leichtes diese exakt zu reproduzieren. Wir haben es hier ganz klassisch mit einem **Overfitting (\u00dcberanpassung)** zu tun. Das Modell hat die Daten sozusagen *auswendig gelernt*.\n",
                "\n",
                "* Die Genauigkeit auf den **Validierungs- und Testdaten** variiert von 80% bis 100%. Qualitativ ist kein wesentlicher Unterschied zwischen Validierung- und Testdaten vorhanden und beide variieren anscheinend zuf\u00e4llig. Auch das \u00fcberrascht uns nicht, denn der Entscheidungsbaum wird nur einmal mit den Trainingsdaten trainiert (`model_dtree.fit()`). Die Evaluierung mit den Validierungsdaten flie\u00dft nicht in ein erneutes Training des Modells ein. Hier sind also Validierung und Test gleichwertig - wenn auch mit anderen Genauigkeiten.\n",
                "\n",
                "* Warum ist die **Genauigkeit** mal auf den Validierungsdaten und mal auf den Testdaten **kleiner als 100%**, obwohl wir doch ein \"Overfitting\" haben? Das liegt schlicht an der zuf\u00e4lligen Aufteilung der Daten. Manchmal passt - durch Zufall - die Charakteristik der Validierungs- oder der Testdaten eben genau zu den auswendig gelernten Trainingsdaten, und manchmal nicht. Das Modell kennt eben *nur* die Trainingsdaten.\n",
                "\n",
                "**Was passiert bei der k-fachen Kreuzvalidierung?**\n",
                "\n",
                "* Wie in Kapitel 4.2 des Buchs \"Basiswissen KI-Testen\" erkl\u00e4rt, werden dabei Trainings- *und* Validierungsdaten zum Training verwendet. Ein Entscheidungsbaum mit maximaler Tiefe 8 wird voraussichtlich ebenfalls \u00fcberangepasst sein. Die Genauigkeit f\u00fcr diesen wird jedoch getrennt in mehreren (genauer *k*) Trainings- und Validierungs-Durchl\u00e4ufen berechnet und gemittelt. Hier d\u00fcrfen  wir eine Genauigkeit von unter 100% erwarten."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7da41b7a-2dcc-4cb2-8f6e-3d6ec0c98136",
            "metadata": {
                "tags": []
            },
            "source": [
                "## Zusatzaufgabe 4\n",
                "\n",
                "**Verwende die *k*-fache Kreuzvalidierung f\u00fcr den Entscheidungsbaum.**"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "77b1e766-6fe8-472b-b95c-c943d208dfc4",
            "metadata": {
                "jp-MarkdownHeadingCollapsed": true,
                "tags": []
            },
            "source": [
                "Wenn du diese noch nicht kennst, hier eine kurze Erkl\u00e4rung:\n",
                "#### Die k-fache Kreuzvalidierung kurz erkl\u00e4rt..."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4ccdf477-85e7-41dc-9929-6e57c09581d5",
            "metadata": {
                "jp-MarkdownHeadingCollapsed": true,
                "tags": []
            },
            "source": [
                "Ziel der Kreuzvalidierung ist, *alle* Daten (Trainings- und Validierungsdaten) f\u00fcr das Training eines Modells zu nutzen. Dann fehlen jedoch unabh\u00e4ngige Validierungsdaten. Hier behilft man sich mit dem Trick der Kreuzvalidierung:\n",
                "\n",
                "Die ***k*-fache Kreuzvalidierung** teilt zun\u00e4chst den urspr\u00fcnglichen Datensatz in *k* Bereiche, sogenannte *folds\"*, auf. Dann wird das Modell mit den Daten aus *k*-1 Bereichen trainiert und mit dem letzten, nicht zum Training verwendeten Bereich validiert und erh\u00e4lt beispielsweise eine Genauigkeit. Dies macht man mit allen *k* m\u00f6glichen Verteilungen der folds in Trainings- und Validierungsdaten, wie hier dargestellt:\n",
                "\n",
                "![Image](data/4.2_Methode_k-fold.png)\n",
                "\n",
                "Bei der Einteilung in die folds benutzen die meisten Methoden **Indizes** in die eigentlichen Daten, um die Bereiche und deren Zuordnung zu Trainings- und Validierungsdaten zu identifizieren."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a21e6038-13d9-44c2-b530-160d1f16ecfa",
            "metadata": {},
            "source": [
                "Wir benutzen die Klasse [KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) der Bibliothek scikit-learn, die uns ein python-Objekt zur\u00fcckgibt. Mit diesem k\u00f6nnen wir mit dessen Methode `.split(...)` die Indizes auf die Eingabedaten und Ausgabedaten so aufteilen lassen, dass wir alle *k* Aufteilungen als Liste von Index-S\u00e4tzen zur\u00fcckbekommen.\n",
                "\n",
                "Ein Beispiel soll das zeigen:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "76ed07d1-c0e0-4109-ae02-59b1a4df302c",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "from sklearn.model_selection import KFold    # Wir nutzen die Klasse 'KFold' der Bibliothek scikit-learn\n",
                "\n",
                "# Wir Definieren mit Hilfe der Klasse KFold eine 4-fach Kreuzvalidierung (ohne zuf\u00e4lliger Verteilung) mit Namen 'fourfold':\n",
                "fourfold = KFold(n_splits=4)\n",
                "\n",
                "# Wir legen beispielhaft Eingabe- und Ausgabedaten an:\n",
                "X_sample = pd.DataFrame(data={'input 1':range(0,16), 'input 2':range(20,36)})\n",
                "y_sample = pd.DataFrame(data={'output':range(0,16)})\n",
                "\n",
                "# Wir lassen uns f\u00fcr die Datenpunkte der Eingabedaten `X_sample` die 4 Indizes-Kombinationen f\u00fcr Training und Validierung ausgeben\n",
                "for (i_train, i_val) in fourfold.split(X_sample):\n",
                "    print(f\"Indizes f\u00fcr Training: {i_train} und Validierung: {i_val}\")\n",
                "    # um \u00fcber die Indizes auf die Daten zuzugreifen, einfach den .iloc[...] Index benutzen:\n",
                "    # print(X_sample.iloc[i_train])  # Das sind die Trainignsdaten f\u00fcr die Eingaben \n",
                "    # print(X_sample.iloc[i_val])    # Das sind die Validierungsdaten f\u00fcr die Eingaben\n",
                "    # print(y_sample.iloc[i_train])  # Das sind die Trainignsdaten f\u00fcr die Ausgaben\n",
                "    # print(y_sample.iloc[i_val])    # Das sind die Validierungsdaten f\u00fcr die Ausgaben"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "178d4e26-9fec-4b8b-8232-2fa0ac553ff3",
            "metadata": {},
            "source": [
                "Du kann hier erkennen, dass vier Kombinationen von Trainings- und Testdaten - durch die Indizes ausgedr\u00fcckt - erzeugt werden. Dabei ist jeder der 16 Datenpunkte einmal im Validierungsdatensatz gewesen."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "38b0c540-3698-4817-86db-bc6a32973493",
            "metadata": {},
            "source": [
                "#### Die Kreuzvalidierung angewendet\n",
                "Benutze nun die Klasse KFold, um eine **9-fache** Kreuzvalidierung f\u00fcr einen Entscheidungsbaum wie oben vorzunehmen. F\u00fclle dabei im Code wieder die mit `...` gekennzeichneten Bereiche aus. Wir benutzen dabei die Klasse [KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) der Scikit-learn-Bibliothek mit ihrer Methode [.split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold.split).\n",
                "Du kannst dich wieder an Codeteilen weiter oben orientieren."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "200dca81-9391-4185-b75f-a05bae2e6256",
            "metadata": {
                "tags": [
                    "Aufgabe"
                ]
            },
            "outputs": [],
            "source": [
                "from sklearn.model_selection import KFold    # Wir nutzen die Klasse 'KFold' der Bibliothek scikit-learn\n",
                "\n",
                "# Mit KFold eine 9-fach Kreuzvalidierung definieren\n",
                "folds = KFold(n_splits=...)\n",
                "\n",
                "avg_acc = 0 # Mittlere Genauigkeit mit 0 initialisiern\n",
                "\n",
                "# \u00dcber alle Split-Kombinationen Der Eingaben (X_trainval) und Ausgaben (y_trainval) iterieren und jeweils:\n",
                "for (i_train, i_val) in folds.split(...):\n",
                "    # den Entscheidungsbaum mit maximaler Tiefe 8 anlegen\n",
                "    model_dtree = ...\n",
                "    \n",
                "    # per '.fit()'-Methode mit den Trainigsdaten trainieren. Achtung: i_train sind nur die Indizes, nicht die Daten\n",
                "    model_dtree.fit(...)\n",
                "    \n",
                "    # die Genauigkeit per '.score' anahand ver Validierungsdaten berechnen. Hinweis: benutze i_val\n",
                "    acc = model_dtree.score(...)*100\n",
                "    \n",
                "    print(f\" - Modellgenauigkeit auf den fold-Validierungsdaten liegt bei {acc:3.2f}%\")\n",
                "    avg_acc += acc  # Genauigkeit aufaddieren\n",
                "\n",
                "avg_acc /= ...    # nun noch den Mittelwert aus der akkumulierten Genauigkeiten berechnen:\n",
                "print(f\"Die mittlere Genauigkeit aller Modelle liegt bei {avg_acc:3.2f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2af78485-c246-4416-b1d1-dbef3354bcff",
            "metadata": {
                "tags": [
                    "L\u00f6sung"
                ],
                "jupyter": {
                    "source_hidden": true
                }
            },
            "outputs": [],
            "source": [
                "# Um die L\u00f6sung anzuzeigen, bitte diese Zelle zweimal ausf\u00fchren\n",
                "%load L\u00f6sungen/L\u00f6sung08.py"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0a988dda-730e-45b1-bf0c-cc9c95435dac",
            "metadata": {},
            "source": [
                "Die mittlere Genauigkeit \u00fcber alle *folds* liegt damit unter 100%.\n",
                "\n",
                "Trainiere nun den finalen Entscheidungsbaum mit **allen** Trainings- und Validierungsdaten. Wir postulieren, dass dessen Genauigkeit der oben ermittelten mittleren Genauigkeit entspricht. F\u00fclle wieder die mit `...` gekennzeichneten Codeteile aus"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bf8a5559-9e7b-432d-952d-eb11ec973db0",
            "metadata": {
                "tags": [
                    "Aufgabe"
                ]
            },
            "outputs": [],
            "source": [
                "# Lege den Entscheidungsbaum mit maximaler Tiefe 8 an\n",
                "model_dtree = ...\n",
                "# Trainiere diesen per '.fit()'-Methode mit den Daten\n",
                "model_dtree.fit(...)\n",
                "\n",
                "# und pr\u00fcfe das Modell mit den Testdaten (siehe weiter oben bei genauigkeit()!)\n",
                "acc = model_dtree.score(...)*100\n",
                "\n",
                "# Vergleiche die Genauigkeit aus der k-fachen Kreuzvalidierung und dem Test mit den Testdaten\n",
                "print(f\"Die gesch\u00e4tzte Genauigkeit des Modells mit k-facher Kreuzvalidierung bei {...:3.2f}%\")\n",
                "print(f\"Die            Genauigkeit des Modells mit den Testdaten liegt bei       {...:3.2f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "01d2bcfa-e0b3-4f22-88b7-8f3a48c79411",
            "metadata": {
                "tags": [
                    "L\u00f6sung"
                ],
                "jupyter": {
                    "source_hidden": true
                }
            },
            "outputs": [],
            "source": [
                "# Um die L\u00f6sung anzuzeigen, bitte diese Zelle zweimal ausf\u00fchren\n",
                "%load L\u00f6sungen/L\u00f6sung09.py"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "efd60eef-0fc7-4115-a215-ff6cb89365ab",
            "metadata": {
                "tags": []
            },
            "source": [
                "## Das Modell abspeichern"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "463e4ef0-91b1-4504-9515-dcfad7d37a69",
            "metadata": {
                "tags": []
            },
            "source": [
                "Zum Abschluss wollen wir noch das **Modell** sowie die **Testdaten** abspeichern, denn wir werden beide in [\u00dcbung 5.4 - Evaluation](../Kap05.4_Evaluation/\u00dcbung_Evaluation.ipynb) noch einmal brauchen."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2baca2ef-146f-45b0-a979-749cae949450",
            "metadata": {},
            "source": [
                "Solltest du weiter oben viel mit dem Daten-Split, dem `random_state` und der maximalen Tiefe des Entscheidungsbaums ausprobiert haben, kannst du mit der folgenden Zelle nochmal die Datenaufteilung und das Modelltraining so vornehmen, wie wir es f\u00fcr die \u00dcbungen 5.4 ben\u00f6tigen."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f988eaba-f430-4959-a0c0-396e2b78b750",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# Eingabe- und Ausgabedaten nochmal aufteilen...\n",
                "rs = 4\n",
                "X_trainval, X_test, y_trainval, y_test = train_test_split( X, y, test_size=0.1, random_state=rs )\n",
                "\n",
                "# Den Entscheidungsbaum mit maximaler Tiefe 8 erzeugen und per '.fit()'-Methode mit den Trainigsdaten trainieren...\n",
                "model_dtree = tree.DecisionTreeClassifier(max_depth=8)\n",
                "model_dtree.fit(X_trainval, y_trainval);   # Wir trainieren das Modell mit Trainings- _und_ Validierungsdaten (nach der der Kreuzvalidierung, s.o.)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b8ebc2c8-8e71-4b74-a567-36dd7e74c96f",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "import joblib\n",
                "X_test.to_csv('X_test.csv',  index=False)  # Testdaten-Eingaben speichern\n",
                "y_test.to_csv('y_test.csv',  index=False)  # Testdaten-Ausgaben speichern\n",
                "joblib.dump(model_dtree,\"modell-8.pkl\");   # Modell (maximale Tiefe 8) speichern"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2436f8c8-5789-4feb-adb1-803722fae7f9",
            "metadata": {},
            "source": [
                "Damit haben wir die Dateien, die wir f\u00fcr [\u00dcbung 5.4 - Evaluation](../Kap05.4_Evaluation/\u00dcbung_Evaluation.ipynb) ben\u00f6tigen, gespeichert."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        },
        "toc-autonumbering": false,
        "toc-showcode": false,
        "toc-showmarkdowntxt": false,
        "toc-showtags": false
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
